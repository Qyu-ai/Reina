{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIvb0JodYx9d"
   },
   "source": [
    "## Import reina and other necessary libraries. Initialize a spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9mGaEKdeU89A"
   },
   "outputs": [],
   "source": [
    "from reina.MetaLearners import SLearner\n",
    "from reina.MetaLearners import TLearner\n",
    "from reina.MetaLearners import XLearner\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Initialize spark session\n",
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName('Meta-Learner-Spark') \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNHXEHMOY9PY"
   },
   "source": [
    "## Read toy data. Replace .load() with the test_data.csv location -- this location could be a local one (no cluster) or it could be on a distributed storage system (e.g., HDFS)\n",
    "\n",
    "*Note: Code below assumes data generated by our script (for specifics, please refer to our toy data generation in the README). You could also modify the code accordingly to use your own data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "DZyUrMTBVJAf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(SeniorCitizen,IntegerType,true),StructField(Dependents,StringType,true),StructField(tenure,IntegerType,true),StructField(PhoneService,StringType,true),StructField(MultipleLines,StringType,true),StructField(InternetService,StringType,true),StructField(OnlineSecurity,StringType,true),StructField(OnlineBackup,StringType,true),StructField(DeviceProtection,StringType,true),StructField(TechSupport,StringType,true),StructField(StreamingTV,StringType,true),StructField(StreamingMovies,StringType,true),StructField(Contract,StringType,true),StructField(PaperlessBilling,StringType,true),StructField(MonthlyCharges,DoubleType,true),StructField(TotalCharges,StringType,true),StructField(Churn,StringType,true)))\n",
      "+-------------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------+------------+-----+\n",
      "|SeniorCitizen|Dependents|tenure|PhoneService|   MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|MonthlyCharges|TotalCharges|Churn|\n",
      "+-------------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------+------------+-----+\n",
      "|            0|        No|     1|          No|No phone service|            DSL|            No|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|         29.85|       29.85|   No|\n",
      "|            0|        No|    34|         Yes|              No|            DSL|           Yes|          No|             Yes|         No|         No|             No|      One year|              No|         56.95|      1889.5|   No|\n",
      "|            0|        No|     2|         Yes|              No|            DSL|           Yes|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|         53.85|      108.15|  Yes|\n",
      "|            0|        No|    45|          No|No phone service|            DSL|           Yes|          No|             Yes|        Yes|         No|             No|      One year|              No|          42.3|     1840.75|   No|\n",
      "|            0|        No|     2|         Yes|              No|    Fiber optic|            No|          No|              No|         No|         No|             No|Month-to-month|             Yes|          70.7|      151.65|  Yes|\n",
      "+-------------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "          .format(\"csv\") \\\n",
    "          .option('header', 'true') \\\n",
    "          .option(\"inferSchema\" , \"true\")\\\n",
    "          .load(\"../../telco-churn.csv\")  # replace with the location of test_data.csv\n",
    "\n",
    "# Drop columns not needed\n",
    "df = df.drop(\"customerID\")\n",
    "df = df.drop(\"gender\")\n",
    "df = df.drop(\"partner\")\n",
    "df = df.drop(\"PaymentMethod\")\n",
    "\n",
    "# Print out dataframe schema\n",
    "print(df.schema)\n",
    "print(df.show(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix some data types...\n",
    "df = df.withColumn(\"TotalCharges\", df.TotalCharges.cast(\"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform categorical data using string index and dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "categorical_feats = [\"Dependents\", \"PhoneService\", \"MultipleLines\", \"InternetService\", \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\", \"StreamingTV\", \"StreamingMovies\", \"Contract\", \"PaperlessBilling\", \"Churn\"]\n",
    "\n",
    "for feature in categorical_feats:\n",
    "    indexer = StringIndexer(inputCol=feature, outputCol=feature+\"_index\")\n",
    "    df = indexer.fit(df).transform(df)\n",
    "    df = df.drop(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "one_hot_features = [\"MultipleLines_index\", \"InternetService_index\", \"Contract_index\"]\n",
    "\n",
    "\n",
    "for feature in one_hot_features:\n",
    "    encoder = OneHotEncoder(inputCol=feature, outputCol=feature+\"_ohe\")\n",
    "    df = encoder.fit(df).transform(df)\n",
    "    df.drop(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Xa3QohmXg2Y"
   },
   "source": [
    "## S-leaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 20)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7032, 20)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "df = df.dropna()\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "BkMiSReQW2DE"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-f23f2185d609>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Get heterogeneous treatment effects (cate for individual samples and ate for averaged treatment effect)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mcate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark_slearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtreatment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtreatments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\reina\\MetaLearners\\SLearner.py\u001b[0m in \u001b[0;36meffects\u001b[1;34m(self, X, treatment)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;31m# Get cate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mX_w_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mergeDfCol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[0mX_w_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mergeDfCol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_w_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtreatment\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_w_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_w_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX_w_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"(prediction_1 - prediction_0)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\reina\\MetaLearners\\SLearner.py\u001b[0m in \u001b[0;36m__mergeDfCol\u001b[1;34m(self, df_1, df_2)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mdf_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"COL_MERGE_ID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonotonically_increasing_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mdf_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"COL_MERGE_ID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonotonically_increasing_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mdf_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"COL_MERGE_ID\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"COL_MERGE_ID\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf_3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "# Set up necessary parameters\n",
    "treatments = ['PhoneService_index']\n",
    "outcome = 'Churn_index'\n",
    "\n",
    "# Arbitrary estimator. Can replace with other ML algo.\n",
    "estimator = RandomForestRegressor(featuresCol=\"features\", labelCol=outcome)\n",
    "\n",
    "# Fit S-learner\n",
    "spark_slearner = SLearner()\n",
    "spark_slearner.fit(data=df, treatments=treatments, outcome=outcome, estimator=estimator)\n",
    "\n",
    "# Get heterogeneous treatment effects (cate for individual samples and ate for averaged treatment effect)\n",
    "cate, ate = spark_slearner.effects(X=df, treatment=treatments[0])\n",
    "print(cate)\n",
    "print(ate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1fcO5LOXjH_"
   },
   "source": [
    "## T-leaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kn1QYEJPXWvM"
   },
   "outputs": [],
   "source": [
    "# Set up necessary parameters\n",
    "treatments = ['treatment']\n",
    "outcome = 'outcome'\n",
    "\n",
    "# Arbitrary estimators. Can replace with other ML algo.\n",
    "estimator_1 = RandomForestRegressor()\n",
    "estimator_0 = RandomForestRegressor()\n",
    "\n",
    "# Fit T-learner\n",
    "spark_tlearner = TLearner()\n",
    "spark_tlearner.fit(data=df, treatments=treatments, outcome=outcome,\n",
    "                   estimator_0=estimator_0, estimator_1=estimator_1)\n",
    "\n",
    "# Get heterogeneous treatment effects (cate for individual samples and ate for averaged treatment effect)\n",
    "cate, ate = spark_tlearner.effects()\n",
    "print(cate)\n",
    "print(ate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxZQdw1fXoPa"
   },
   "source": [
    "## X-leaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qj1owlx-XYKo"
   },
   "outputs": [],
   "source": [
    "# Set up necessary parameters\n",
    "treatments = ['treatment']\n",
    "outcome = 'outcome'\n",
    "\n",
    "# Arbitrary estimators. Can replace with other ML algo.\n",
    "estimator_11 = RandomForestRegressor()\n",
    "estimator_10 = RandomForestRegressor()\n",
    "estimator_21 = RandomForestRegressor()\n",
    "estimator_20 = RandomForestRegressor()\n",
    "propensity_estimator = RandomForestClassifier()\n",
    "\n",
    "# Fit X-learner\n",
    "spark_xlearner = XLearner()\n",
    "spark_xlearner.fit(data=df, treatments=treatments, outcome=outcome, \n",
    "                       estimator_10=estimator_10, estimator_11=estimator_11, \n",
    "                       estimator_20=estimator_20, estimator_21=estimator_21,\n",
    "                       propensity_estimator=propensity_estimator)\n",
    "\n",
    "# Get heterogeneous treatment effects (cate for individual samples and ate for averaged treatment effect)\n",
    "cate, ate = spark_xlearner.effects()\n",
    "print(cate)\n",
    "print(ate)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
