{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIvb0JodYx9d"
      },
      "source": [
        "#### Import reina and other necessary libraries. Initialize a spark session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mGaEKdeU89A"
      },
      "source": [
        "from reina.MetaLearners import SparkSLearner\n",
        "from reina.MetaLearners import SparkTLearner\n",
        "from reina.MetaLearners import SparkXLearner\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize spark session\n",
        "spark = SparkSession \\\n",
        "            .builder \\\n",
        "            .appName('Meta-Learner-Spark') \\\n",
        "            .getOrCreate()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNHXEHMOY9PY"
      },
      "source": [
        "#### Read toy data. Replace .load() with the test_data.csv location -- this location could be a local one (no cluster) or it could be on a distributed storage system (e.g., HDFS)\n",
        "\n",
        "*Note: Code below assumes data generated by our script (for specifics, please refer to our toy data generation in the README). You could also modify the code accordingly to use your own data.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZyUrMTBVJAf"
      },
      "source": [
        "df = spark.read \\\n",
        "          .format(\"csv\") \\\n",
        "          .option('header', 'true') \\\n",
        "          .load(\"test_data.csv\")  # replace with the location of test_data.csv\n",
        "\n",
        "# Case variables to appropriate types\n",
        "df = df.withColumn(\"var1\", df.var1.cast(\"float\"))\n",
        "df = df.withColumn(\"var2\", df.var2.cast(\"float\"))\n",
        "df = df.withColumn(\"var3\", df.var3.cast(\"float\"))\n",
        "df = df.withColumn(\"var4\", df.var4.cast(\"float\"))\n",
        "df = df.withColumn(\"var5\", df.var5.cast(\"float\"))\n",
        "df = df.withColumn(\"treatment\", df.treatment.cast(\"float\"))\n",
        "df = df.withColumn(\"outcome\", df.outcome.cast(\"float\"))\n",
        "\n",
        "# Drop garbage column\n",
        "df = df.drop(\"_c0\")\n",
        "\n",
        "# Print out dataframe schema\n",
        "print(df.schema)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xa3QohmXg2Y"
      },
      "source": [
        "## S-leaner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkMiSReQW2DE"
      },
      "source": [
        "# Set up necessary parameters\n",
        "treatments = ['treatment']\n",
        "outcome = 'outcome'\n",
        "\n",
        "# Arbitrary estimator. Can replace with other ML algo.\n",
        "estimator = RandomForestRegressor()\n",
        "\n",
        "# Fit S-learner\n",
        "spark_slearner = SparkSLearner()\n",
        "spark_slearner.fit(data=df, treatments=treatments, outcome=outcome, estimator=estimator)\n",
        "\n",
        "# Get heterogeneous treatment effects (cate for individual samples and ate for averaged treatment effect)\n",
        "cate, ate = spark_slearner.effects()\n",
        "print(cate)\n",
        "print(ate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1fcO5LOXjH_"
      },
      "source": [
        "## T-leaner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn1QYEJPXWvM"
      },
      "source": [
        "# Set up necessary parameters\n",
        "treatments = ['treatment']\n",
        "outcome = 'outcome'\n",
        "\n",
        "# Arbitrary estimators. Can replace with other ML algo.\n",
        "estimator_1 = RandomForestRegressor()\n",
        "estimator_0 = RandomForestRegressor()\n",
        "\n",
        "# Fit T-learner\n",
        "spark_tlearner = SparkTLearner()\n",
        "spark_tlearner.fit(data=df, treatments=treatments, outcome=outcome,\n",
        "                   estimator_0=estimator_0, estimator_1=estimator_1)\n",
        "\n",
        "# Get heterogeneous treatment effects (cate for individual samples and ate for averaged treatment effect)\n",
        "cate, ate = spark_tlearner.effects()\n",
        "print(cate)\n",
        "print(ate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxZQdw1fXoPa"
      },
      "source": [
        "## X-leaner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj1owlx-XYKo"
      },
      "source": [
        "# Set up necessary parameters\n",
        "treatments = ['treatment']\n",
        "outcome = 'outcome'\n",
        "\n",
        "# Arbitrary estimators. Can replace with other ML algo.\n",
        "estimator_11 = RandomForestRegressor()\n",
        "estimator_10 = RandomForestRegressor()\n",
        "estimator_21 = RandomForestRegressor()\n",
        "estimator_20 = RandomForestRegressor()\n",
        "propensity_estimator = RandomForestClassifier()\n",
        "\n",
        "# Fit X-learner\n",
        "spark_xlearner = SparkXLearner()\n",
        "spark_xlearner.fit(data=df, treatments=treatments, outcome=outcome, \n",
        "                       estimator_10=estimator_10, estimator_11=estimator_11, \n",
        "                       estimator_20=estimator_20, estimator_21=estimator_21,\n",
        "                       propensity_estimator=propensity_estimator)\n",
        "\n",
        "# Get heterogeneous treatment effects (cate for individual samples and ate for averaged treatment effect)\n",
        "cate, ate = spark_xlearner.effects()\n",
        "print(cate)\n",
        "print(ate)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}